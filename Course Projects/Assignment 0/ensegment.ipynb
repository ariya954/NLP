{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ensegment: default program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from default import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation\n",
    "\n",
    "Write some beautiful documentation of your program here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choose spain\n",
      "this is a test\n",
      "who represents\n",
      "experts exchange\n",
      "speed of art\n",
      "un climate change body\n",
      "we are the people\n",
      "mention your faves\n",
      "now playing\n",
      "the walking dead\n",
      "follow me\n",
      "we are the people\n",
      "mention your faves\n",
      "check domain\n",
      "big rock\n",
      "name cheap\n",
      "apple domains\n",
      "honesty hour\n",
      "being human\n",
      "follow back\n",
      "social media\n",
      "30 seconds to earth\n",
      "current rate sought to go down\n",
      "this is insane\n",
      "what is my name\n",
      "is it time\n",
      "let us go\n",
      "me too\n",
      "now thatcher is dead\n",
      "advice for young journalists\n"
     ]
    }
   ],
   "source": [
    "Pw = Pdist(data=datafile(\"data/count_1w.txt\"))\n",
    "segmenter = Segment(Pw)\n",
    "with open(\"data/input/dev.txt\") as f:\n",
    "    for line in f:\n",
    "        print(\" \".join(segmenter.segment(line.strip())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Do some analysis of the results. What ideas did you try? What worked and what did not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given an input string, the task is to automatically insert spaces so that the output will be a valid sequence of English words. The expected input will be a list of string. The expected output represents the most likely segmentation according to the model.\n",
    "\n",
    "At first, we observed that the probability of the unknown words are uniform (1/N). However, we know that it is less likely to have longer unknown words. Usually, the unknown words are small. So, we included this fact by adding the term 5 ** len(k). In this case, the longer unknown words will have bigger k, and the probability will get exponentially less. By this, we got a result of 0.97 accuracy.\n",
    "\n",
    "Upon further analysis, we observed that unknown tokens in the dataset consist solely of punctuation characters (~, !, @, #, $, %, ^, &, *, (, )), yielding approximately ten possible symbols. Based on this observation, we revised 5 to 10 to have the smoothing term which is 1/(N * 10 ** len(k)). Then, this led to a perfect accuracy (1.00) on the dev set.\n",
    "\n",
    "For the quantitative comparison:\n",
    "\n",
    "| Baseline | 5 ** len(k) | 10 ** len(k) |\n",
    "| -------- | ----------- | ------------ |\n",
    "| 0.82 | 0.97 | 1.00 |\n",
    "\n",
    "\n",
    "For the qualitative comparison:\n",
    "\n",
    "| Baseline | 5 ** len(k) | 10 ** len(k) |\n",
    "| -------- | ----------- | ------------ |\n",
    "| unclimatechangebody | un climate change body | un climate change body |\n",
    "| 30secondstoearth | 30secondstoearth | 30 seconds to earth |\n",
    "\n",
    "So, we can see that for the \"5 ** len(k)\", it successfully segmented the \"unclimatechangebody\" to \"un climate change body\". But it fails to segment the \"30secondstoearth\", whereas the \"10 ** len(k)\" successfully segmented to \"30 seconds to earth\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
